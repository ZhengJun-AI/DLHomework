# 李宏毅深度学习笔记

## Regression

也就是通常所说的回归分析，可用于简单的预测。

* 股票预测
* 自动驾驶的视觉判断系统
* 依据喜好值的推荐系统

### 例一  宝可梦战斗值预测

输入值：$x_{cp}$ 是当前战斗值，$x_S$ 是当前名称，$x_{hp}$ 为当前血量，$x_h$ 为当前身高。

输出值：进化后宝可梦的战斗值。

#### Step 1 : Model

第一步就是猜测可能的函数关系，并且保留一些参数，进行建模。

罗列出一些可能的关系并进行筛选。

不妨假设 $y=b+w\cdot x_{cp}$ ，也就是采用 Linear model : $y=b+\Sigma w_ix_i$

#### Step 2 :  Goodness of Function

也就是评估函数，利用 training data 以及一种方式来判断当然选择的 Model 是否合理。

往往采用残差平方和来进行估计，下面是采用了容量为10的 data set 所列式子。
$$
\begin{aligned}\mathrm{L}(f) &=\mathrm{L}(w, b) \\&=\sum_{n=1}^{10}\left(\hat{y}^{n}-\left(b+w \cdot x_{c p}^{n}\right)\right)^{2}\end{aligned}
$$
事实上可以将函数 $\mathrm{L}(f)$ 视为关于 $w,b$ 的二元函数，绘制图形以后就知道是能够找到使得 $\mathrm{L}(f)$ 最小的 $w,b$ ，方法有两种。

第一种就是视频中介绍的 Gradient Descent，即梯度下降方法。如果不考虑具体实现，只说理论的话倒是很容易理解，直接进行微分，然后向着最低谷前进就是了。与牛顿迭代法有异曲同工之妙。

第二种方法，就是采用最小二乘法，直接用线性代数进行推理。只不过其中涉及了矩阵求导相关知识，略微麻烦一点，这里直接放出结论。
$$
\hat{\boldsymbol{w}}=\left(X^{T} X\right)^{-1} X^{T} \boldsymbol{y}
$$

相关推导过程可以参考附件：OLS.mhtml

#### Step 3 : Gradient Descent

实际上这就是一个不断计算偏微分然后进行迭代的过程，不赘述。

简单地交代一下两个偏微分。
$$
\frac{\partial L}{\partial w}=2\times\sum_{n=1}^{10}(\hat{y}^n-(b+w\cdot x_{cp}^n))\times x_{cp}^n\\
\frac{\partial L}{\partial b}=2\times\sum_{n=1}^{10}(\hat{y}^n-(b+w\cdot x_{cp}^n))\times(-1)
$$
比较值得注意应该是 learning rate 的设置，需要一定的经验与技巧。

#### Model Selection

因为线性拟合显得过于简单，总会让人怀疑这种模型的可靠性，所以在进行评估以后，我们当然还会考虑继续调整模型。一种比较显而易见的方式，就是给原有的函数模型增添参数。

例如：
$$
y=b+w_1\cdot x_{cp}+w_2\cdot(x_{cp})^2\\
y=b+w_1\cdot x_{cp}+w_2\cdot(x_{cp})^2+w_3\cdot(x_{cp})^3
$$
我们当然还可以一直写下去，让函数关系变得越来越复杂。

但是呢，随着函数越来越复杂，在训练集上的表现越来越好，在测试集上的表现却不是随之增强。这就是发生了 overfitting ，即过拟合。

这是我们在寻找和训练模型需要注意的一个重要问题——如何避免过拟合。一种比较好的检验方法自然就是将训练好的函数放在测试集上对比。

事实上呢，我们也可以根据经验来设置函数，不能一味地强求函数的复杂度和对训练集的高拟合程度。加上二次项以后，还可以进行正则化。

![](.\pic/overfitting.png)

#### Hidden factors?

本来分析到这里就应该告一段落了，但是当我们扩大 training set 以后，却发现了一件比较奇妙的事情。

![](.\pic\hidden-factors.png)

就是原CP值和进化后CP值并不是统一的线性关系，根据图像来看，应当还有另外的因素，才会导致形成两条不同的直线。

事实上，分析后会发现还和宝可梦的物种有关系。

#### Back to step 1 : Redesign the Model

一种比较直觉性的做法是，针对不同的物种，分别计算出一种线性关系。

![](.\pic\redesign.png)

当然了，我们也可以利用信号控制的思想，设定一个 $\delta(x_s)$ 函数来辅助，使得上述所有的式子都可以统一在一个函数之中。举例如下：
$$
\delta(x_s=Pidgey)=\\
\left\{\array{=1,& x_s=Pidgey\\
=0,&x_s\neq Pidgey}
\right.
$$

#### Back to step 2 : Regularization

这里就介绍一种避免过拟合的方式，就是正则化。
$$
\begin{aligned}
&y=b+\sum w_{i} x_{i}\\
&L=\sum_{n}\left(\hat{y}^{n}-\left(b+\sum w_{i} x_{i}\right)\right)^{2}+\lambda \sum\left(w_{i}\right)^{2}
\end{aligned}
$$
实际上就是加上一个控制系数 $\lambda$ ，避免某系数过大。这样的原理是——系数越小，所形成的函数就会越平滑，对于输入越不敏感，受到噪音的影响就会比较小。

但是过于平滑的函数，也很难带来优秀的结果。

![](.\pic\regularization.png)

## Gradient Descent

$$
\left[\begin{array}{}
    \theta_1^1  \\ 
    \theta_2^2
\end{array}\right]
=
\left[\begin{array}{}
{\theta_1^0\\\theta_2^0}
\end{array}\right]
-\eta
\left[\begin{array}{}
\frac{\partial L(\theta_1^0)}{\partial\theta_1}\\
\frac{\partial L(\theta_2^0)}{\partial \theta_2}
\end{array}\right]
$$

梯度下降的核心公式就是上面的式子(两个参数)，所谓的“梯度”其实就是指对每个参数的偏微分。

### Tip : Tuning your learning rates

上面其实已经提到了 learning rate 的问题，如果太小的话会导致梯度下降的过程过慢，如果太大的话就更麻烦，可能永远也达不到谷底，甚至导致 loss function 的结果越来越大。

#### Adaptive Learning Rates

一种通用的方法就是 learning rate 会随着参数变化。

举个例子，可以让其随着迭代次数增大而变小。如 $\eta^t=\frac{\eta}{\sqrt{t+1}}$

#### Adagrad

这种方法的目标在于给每个参数不同的 learning rate，因此它调整 learning rate 的依据与每个参数本身相关。

对于单个参数 $w$，再进行迭代的时候多考虑一个控制变量 $\sigma^t$，这个变量表示当前变量的前 $t$ 次迭代过程中的偏微分的标准差(即平方和的平均数再开根号，也称作 root mean sqare)。
$$
\begin{aligned}
&\begin{aligned}
w^{1} \leftarrow w^{0}-\frac{\eta^{0}}{\sigma^{0}} g^{0} &&&\sigma^{0}=\sqrt{\left(g^{0}\right)^{2}} \\
w^{2} \leftarrow w^{1}-\frac{\eta^{1}}{\sigma^{1}} g^{1}  
&&& \sigma^{1}=\sqrt{\frac{1}{2}\left[\left(g^{0}\right)^{2}+\left(g^{1}\right)^{2}\right]}\\
w^{3} \leftarrow w^{2}-\frac{\eta^{2}}{\sigma^{2}} g^{2} &&&\sigma^{2}=\sqrt{\frac{1}{3}\left[\left(g^{0}\right)^{2}+\left(g^{1}\right)^{2}+\left(g^{2}\right)^{2}\right]}\\
\end{aligned}\\
&\begin{array}{cc}
\vdots & \\
\vdots & & \\
w^{t+1} \leftarrow w^{t}-\frac{\eta^{t}}{\sigma^{t}} g^{t} & &\sigma^{t}  =\sqrt{\frac{1}{t+1} \sum_{i=0}^{t}\left(g^{i}\right)^{2}}
\end{array}
\end{aligned}
$$
迭代过程大体如上。

而实际上又可以化简如下：

![](.\pic\adagrad.png)

另外我们会发现一个事实：如果梯度越大，我们的控制变量就会使整个步伐变小；如果梯度太小，控制变量又会导致步伐变大。我个人觉得这是比较符合直觉的，因为当梯度小相对平缓的时候，确实应当是跨大步行进，而梯度大的时候，很容易骤降到最优值，反而需要谨慎地前进。

本课视频中利用二次函数，直观说明了在设置 learning rate 时如果仅考虑一次导数，无法得到最优解，往往还需要考虑**二次导数**(当然了，我个人认为这个是与参数数目相关的，可以不断拓展，但是考虑到对于算力的要求，也只能保留比重大的因素)。

![](.\pic\double-derivation.png)

随即，老师结合了上面所说的这个利用二次导数的理念，解释了 Adagrad 的某种合理性——即将 $\sqrt{\Sigma_{i=0}^{t}(g^i)^2}$ 这一项视为二次导数。虽然有些牵强，但是确实可以看出这一个控制项与二次导数存在着正相关的联系，且为了节约算力，这也是一种不错的解决方案。

### Stochastic Gradient Descent

![](.\pic\stochastic.png)

这种 gradient descent 的方法就是每次只对一个参数进行操作。并且再评估当前的参数值，计算 loss function 时只随机取一个样本来估计。

这样的好处其实非常显然。

原来的 gradient descent 在评估时考虑所有样本，那我们考虑到那些样本所携带的信息其实相当于开始的时候就利用完了，后面多次重复利用。感性地理解，这样的利用方式会导致效率的低下。

而 stochastic gradient descent 每次评估时只考虑一个样本，并且只考虑一个参数。显然可以直观地看到，这样即便当前样本的偏差较大，对于所有的参数影响不大，因为只关系到当前的参数。而且这样一来，每个样本的信息利用率就提高了，可以显著提升训练模型的速度。

做个比喻的话，原始的 gradient descent 就像是一个万能工匠，不停更换着各种工具敲敲打打造模型；而 stochastic gradient descent 更像是现代的流水线作业，把不同的部分分工给不同车间，各部分造好了以后再组合起来。

### Feature Scaling

其实就是说对所有的参数进行量纲(其实是大小)的调整，使得 rescale 后它们的数值大小相近，处于同一个范围内。这么做的好处是显然的，那就是我们在后面设置参数时可以不用担心因为参数的大小引发各种奇怪的问题。

事实上，这是在模型训练之前，应当对数据进行的处理。

![](.\pic\scaling.png)

### Gradient descent theory

接下来就要讲解梯度下降方法背后的数学原理。

#### Taylor Series

也就是泰勒展开，对于一元函数，借助泰勒展开可以得到一个近似$h(x)\approx h(x_0)+h'(x_0)(x-x_0)$

#### Multivariable Taylor Series

对于多元函数，例如二元函数，事实上也可以进行泰勒展开。
$$
h(x, y)=h\left(x_{0}, y_{0}\right)+\frac{\partial h\left(x_{0}, y_{0}\right)}{\partial x}\left(x-x_{0}\right)+\frac{\partial h\left(x_{0}, y_{0}\right)}{\partial y}\left(y-y_{0}\right)+\cdots
$$
因此也可以得到近似，即保留前三项。

#### Gradient descent - two variables

现在就讲述上面的近似的具体应用。其实就是在我们update参数的过程中，需要用到上面的近似来简化这个运算过程。

假设目前只有两个参数，然后我们有一个cost function来评估目前的参数，接下来就是要改进参数。
$$
\mathrm{L}(\theta) \approx \mathrm{L}(a, b)+\frac{\partial \mathrm{L}(a, b)}{\partial \theta_{1}}\left(\theta_{1}-a\right)+\frac{\partial \mathrm{L}(a, b)}{\partial \theta_{2}}\left(\theta_{2}-b\right)
$$
需要注意的是，上面式子里的偏微分实则是常数，那么现在就让我们看看，如何对优化后的cost function求minimum。

假设我们给参数变化划定了一个范围，实际上也就是learning rate的功效，事实上可以等价成一个简单的式子——$(\theta_1-a)^2+(\theta_2-b)^2\leq  d^2$，其实用几何直观理解可能更好一些，本质上就是局限在一个圆内。

然后事实上，利用向量的数量积的知识就可以直接得出答案，也即如何更新参数可以马上得到minimum，详情参见下图。

![](.\pic\descent.png)
$$
\left[\begin{array}{l}
\theta_{1} \\
\theta_{2}
\end{array}\right]=\left[\begin{array}{l}
a \\
b
\end{array}\right]-\eta\left[\begin{array}{l}
u \\
v
\end{array}\right]=\left[\begin{array}{l}
a \\
b
\end{array}\right]-\eta\left[\begin{array}{c}
\frac{\partial C(a, b)}{\partial \theta_{1}} \\
\frac{\partial C(a, b)}{\partial \theta_{2}}
\end{array}\right]
$$
上面式子中的 $\eta$ 就是learning rate，所以根据上面的推导过程，我们也就知道了为何learning rate一般都设置成**较小值**——因为泰勒展开得到的近似必须在 $\Delta x$ 较小时才相对准确。

#### More Limitation of Gradient Descent

朴素的梯度下降会存在着不少的问题。

* 过程中的偏微分较小，导致参数运动得十分缓慢，甚至是停下来。但实际上距离谷底仍有较大距离。
* 走到了局部最优值，无法达到全局最优。
* ……

![](.\pic\limitation.png)

## The Next Step for Machine Learning

这个部分主要是杂谈机器学习的现状以及我们需要注意的一些问题。

首先，老师举了个汉斯马识数的例子告诉我们，需要关注到机器学习背后的具体识别方式，关注**特征提取**的真实过程，避免发生一系列过拟合或者是学习到无关特征的问题。

然后还介绍了在计算机图形学中，需要避免Adversarial Attack，亦即噪音的影响。

老师还类比了Life-Long Learning，也就是涉及到机器学习是否能利用其他领域的数据和学习经验来辅助解决当前领域的问题，事实上这个就是对AGI的思考。一个模型解决一个问题，这种现象称之为Catastrophic Forgetting。

老师还提到了一种思路，就是让机器自己设计出能够进行自动学习的程序，也即Meta-learning。

关于当前训练模型所需要过多的data，老师还提到了两种learning——Few-Shot learning和Zero-shot learning，前者指少量数据进行训练，后者指无数据训练。对于后者，举例说明，如图像识别，仅提供给机器以文字说明，让其像人一样去识别图片中的动物。

最后总结一下一些问题以及畅想：

* Anomaly Detection(机器能不能知道“我不知道”)
* Explainable AI(说出为什么“我知道”)
* 防止Adversarial Attack
* Life-Long Learning(终身学习)
* Meta-Learning/Zero-Shot Learning(一定需要很多训练资料吗?)
* 增强式学习真的能用吗?
* Network Compression(神经网络压缩)
* 如果训练资料和测试资料很不一样…

## Where does the error com from

在这部分中，主要学习区分误差的来源，即分析出模型的误差到底是来自于bias还是variance。

### Bias and Variance of Estimator

老师首先介绍了一个简单的案例，就是说给出一个无穷序列，然后去估算这个序列的平均值和方差。

一种直接的思路就是从序列内取出$N$个数$\{x^1,x^2,x^3,\cdots\}$，计算其平均值$m$和方差的观测值$s^2$，多次重复，从而进行估算。

然后，老师还对上面对两个统计值的Estimator做了分类——前者是unbiased，后者是Biased。具体说明如下：
$$
m=\frac{1}{N}\sum x^n\neq \mu\\
E[m]=E[\frac{1}{N}\sum x^n]=\frac{1}{N}\sum E[x^n]=\mu\\
s^2=\frac{1}{N}\sum (x^n-m)^2\\
E[s^2]=\frac{N-1}{N}\sigma^2\neq \sigma ^2
$$
简单地说，也就是对平均数的估计是“无偏差”的，而对方差的估计总是有偏差的。

接下来，老师用一张图生动形象地说明了打手枪的过程中，bias和variance分别为高和低时的示例图。

![](.\pic\errors-from-bias-variance.png)

### Parallel Universes

在这个“平行宇宙”案例中，老师借助不同数据的分布不同，进而来评估不同模型的复杂度与variance误差的关系。

所谓“平行宇宙”，其实就是从原始数据集得到一些分布有微小差异的部分数据集，然后用它们来训练模型，看看同一模型在不同的小数据集下面的结果。

![](.\pic\stability.png)

从图中可以看出，复杂度越高的model，variance非常大，表现在图像上就是每个平行宇宙的拟合曲线都差异很大——事实上也就是发生了over fitting。显然采用复杂度小一些的model会好很多。

![](.\pic\bias.png)

上图中，黑线代表原始函数$f^*$，红线代表model拟合的结果，蓝线代表所有model的平均值。当老师讲所有平行宇宙的model取平均以后，却出现了比较神奇的结果——复杂度越高的model，总体看上去十分凌乱，给人以over fitting的感觉，平均下来以后却十分接近正确结果。

对此，老师的解释是：将bias看成是**初始锚点**的话，model就是在不断地在相对于初始锚点进行调整。可以理解为复杂度低的model的覆盖范围小，可能根本就覆盖不到靶心，所以尽力调整以后也就是上图左边的结果，依旧有不少偏差。而复杂的model覆盖范围大，model在training过程中不断调适，最后也就能够整体围绕着靶心了，平均结果当然很好。

总结来说：

* 简单的model，Large Bias and Small Variance，也就是under fitting
* 复杂的model，Small Bias and Large Variance，也就是over fitting

因此我们在综合考虑两种因素后，才能选择到合适的结果。

### What to do with large bias/large variance?

* Diagnosis:

  * 如果你的model无法很好地fit那些training data，那就是large bias，即under fitting
  * 如果你的model可以很好地fit the training data，但是在testing data上面表现很差，那显然就是over fitting，有large variance

* For bias, redesign your model:

  * Add more features as input
  * A more complex model

* For variance:

  * More data![](.\pic\more-data.png)

  * Regularization
    相比追求更大的dataset，正则化是一种不错的选择。一般的具体做法就是在loss function里面加上高次项系数的控制参数。

### Model Selection

这部分主要是老师讲解如何挑选model，以及在挑选过程中要注意的问题。

#### Cross Validation

也就是交叉验证，举个例子，如kaggle上面的作业有public rank可以看到目前的model应用在testing data中的error。同时，如果我们将原有的training set划分出一部分作为validation set用作交叉验证。那么我们只要对比model在另外这两个dataset上面的表现就知道有没有over fitting了。

![](.\pic\corss-validation.png)

#### N-fold Cross Validation

其实也和上面的交叉验证差不多的。同样是划分出不同的dataset进行训练，再取平均值之类的而已。

![](.\pic\N-fold.png)

## Classification

分类问题也是生活中常见的一类问题。

* 信用卡评级
* 诊断疾病
* 手写识别

### 例子：宝可梦属性分类

首先就需要抽象出一些feature来描述pokemon，按照老师的方法可以得到七个feature：Total/HP/Attack/Defence/SP Atk/SP Def/Speed

#### How to do Classification

首先，我们会试图从已学知识来考虑，看看能否用学过的Regression来解决分类问题，但是是不行的，老师举了一个例子来进行说明。

![](.\pic\classification-regression.png)

就像在右图中，其实最好的一种划分应该是绿色的线，但是根据loss function，regression最后出来的结果却可能是像紫线一样——因为右下角远处有一大团点，为了让loss function变小，model会不由自主地往右下偏。

看起来倒像是loss function的锅，不过好像也没法解决。

上面是用regression来处理二元分类，当然了或许也有人会试图用来处理多元分类，将每一类分别对应到连续整数，但是那样子会有一个更大的问题——假定了相邻两类之间存在着某种联系，而实际上可能是没有的。

#### Ideal Alternatives

![](.\pic\ideal-alternatives.png)

事实上还可以想到一种方案，那就是在$f(x)$内嵌套一个$g(x)$，然后再来进行二元分类，loss function不再是之前的样子，而是变成统计错误答案。这咋一听感觉和上面所说的利用regression好像差不多，其实很不同，因为这里的$g(x)$没有限制。

但是采用这种方法的问题也很显然，那就是loss function不能微分。而我们所学的gradient descent是依靠于对loss function的微分来进行的。

然后，在讲述具体做法之前，老师介绍了概率论的知识。

![](.\pic\probability.png)

然后提出了一种方案——利用贝叶斯公式，将概率值作为训练的目标。

随即老师举了例子，依旧是研究如何预测宝可梦属性。假设现在有training data，然后我们要做的二元分类是水系$C_1$和普通系$C_2$。dataset的大小是140，其中79只水系和61只普通系，那么就有$P(C_1)=\frac{79}{160},P(C_2)=\frac{61}{160}$.

接下来的目标就是计算出$P(x|C_1)$，这个时候就肯定要用到之前定下的features来进行训练了。

![](.\pic\probability-frature.png)

为了便于可视化进行理解，上图中只囊括了Defense和SP Defense两个feature，对于n个feature的情况也是差不多的。那么问题就是，如何根据已知的情况得出那只海龟的$P(x|C_1)$？

#### Gaussian

其实当老师画出那个圈以后，我就有了思路——考虑所有水系宝可梦的features都符合同一个概率分布，那么显然就有办法可以得出海龟的对应概率值了。

而老师介绍的方法就是去拟合一个高斯分布。下面给出对应的资料链接。

[高斯分布]: https://blog.slinuxer.com/tag/pca

![](.\pic\gaussian.png)

根据training data，我们可以很容易地计算出需要的$\mu,\Sigma$，从而得到对应的高斯分布函数。但是我们需要注意的是，这个training data只是真实的所有水系宝可梦的一个子集，而全集所对应的那个Gaussian肯定不是我们直接计算出来的这个。

因此我们就有了训练的目标，记$L(\mu,\Sigma)$为Gaussian中sample出这79个点的概率，那显然只需要将这79个点代入函数中，再用乘法公式计算就可以了。不用多说，目标就是最大化$L(\mu,\Sigma )$.

而事实上，这就和regression一样有公式解如下。

![](.\pic\likelyhood.png)

那当我们成功地得到分布以后，就可以回到之前利用贝叶斯公式推导的式子那里，开始进行预测。

![](.\pic\water-classification.png)

这个方法就这么结束了。可惜最后的accuracy只有54%。其实我也后面也看出了一点端倪——虽然看上去引入了概率论的内容使得model看上去像是复杂的曲线，但是实际操作过程却是线性的，而且感觉太过于粗糙，所以结果不佳也是理所当然了。

#### Modifying Model

由于准确率太低，所以考虑改进model，老师提出了一种改进的方式——让上述的两个$L$函数采用相同的协方差矩阵$\Sigma$。

![](.\pic\same-cov.png)

同样地，最优解也是可以由**公式直接给出**，运算量依旧很低。同时，老师还揭示了一个事实——当这两个$L$函数采用相同的协方差矩阵时，所获得的划分边界是linear，而非之前的曲线。

更神奇的是，其accuracy提升到了73%！！！

![](.\pic\boundary.png)

#### Three Steps

最后就来总结一下这一P内讲的classification的方法。

![](.\pic\three-steps.png)

#### Probability Distribution

事实上当然可以不用Gaussian，还可以选择别的分布来计算概率。例如说当只有两个类别的时候，可以选择伯努利分布。老师还说了，如果将一个样本(含有n个feature)的列向量分解掉进行处理，并且假定彼此相互独立，得到的结果是不好的。因为很明显，一只宝可梦的各个指标之间当然是存在着某些正相关关系的。

而那种假定彼此之间相互独立的方法，叫做朴素贝叶斯分布。

![](.\pic\naive-bayes.png)

### Posterior Probability

后验概率。
$$
P\left(C_{1} | x\right)=\frac{P\left(x | C_{1}\right) P\left(C_{1}\right)}{P\left(x | C_{1}\right) P\left(C_{1}\right)+P\left(x | C_{2}\right) P\left(C_{2}\right)}\\
=\frac{1}{1+\frac{P\left(x | C_{2}\right) P\left(C_{2}\right)}{P\left(x | C_{1}\right) P\left(C_{1}\right)}}=\frac{1}{1+\exp (-z)}=\sigma(z)\\

z=\ln \frac{P\left(x | C_{1}\right) P\left(C_{1}\right)}{P\left(x | C_{2}\right) P\left(C_{2}\right)}
$$
这样一来，就将问题转化成参数$z$上面去了。而函数$\sigma(z)$是关于$(0,0.5)$对称的一个函数，还具有着比较良好的性质。

经过一系列推导，最后发现其实$z$可以写成$z=\mathbb{w^T}x+b$的形式。

![](.\pic\z-prof.png)

![](.\pic\P-prof.png)

## Logistic Regression

上面的那个函数实际上也就是逻辑斯蒂方程。

### Step 1 : Function Set

$$
f_{w, b}(x)=P_{w, b}\left(C_{1} | x\right)=\sigma(z)\\
z=w \cdot x+b=\sum_{i} w_{i} x_{i}+b\\
\sigma(z)=\frac{1}{1+\exp (-z)}
$$

### Step 2 : Goodness of a Function

![](.\pic\goodness-of-logistic.png)
$$
L(w, b)=f_{w, b}\left(x^{1}\right) f_{w, b}\left(x^{2}\right)\left(1-f_{w, b}\left(x^{3}\right)\right) \cdots f_{w, b}\left(x^{N}\right)
$$
事实上这个loss function与之前的没有很大的区别。但是因为写成上面这种形式不便于统一，所以又规定了参数$\hat{y}$的取值，然后再进行一系列简化。

![](.\pic\cross-entropy.png)

然后就可以发现，简化后$L(w,b)$内的每一项实际上都是交叉熵(cross entropy)，简单地说，$H(p,q)$就是衡量两个概率分布$p,q$之间的相似程度，在上面可以看到$p$是真实的分布情况，$q$是我们的model的估计值。

当$p,q$分布完全相同时，就有$H(p,q)_{min}$。
当二者正好完全相悖时，取到$H(p,q)_{max}$。

因此利用$H(p,q)$作为loss function实在是再合适不过了。

下面是两种regression的comparison。

![](.\pic\comparasion.png)

### Step 3 : Find best function

这个过程当然也是微分了，这个推导过程十分优美，结果也很美，可以细细地欣赏。

![](.\pic\partial-z-1.png)

![](.\pic\partial-z-2.png)

最后化简$\frac{-\ln L(W, b)}{\partial W_{i}}$出来的结果十分优美。
$$
\frac{-\ln L(W, b)}{\partial W_{i}}=\sum_{n}-\left(\hat{y}^{n}-f_{w, b}\left(x^{n}\right)\right) x_{i}^{n}
$$
![](.\pic\partial-z-3.png)

![](.\pic\comparision.png)

最神奇的事情来了——我们会发现，logistic regression和linear regression的更新式子完全一样(这时候linear regression的loss function乘以$\frac{1}{2}$)。这件事情本身有点奇妙。

### Logistic Regression + Square Error

上面说到了不使用square error作为loss function，这里就给出解释。

事先记一下常见函数的偏导数。
$$
z=\mathbb{w}^Tx+b\\
f_{w,b}(x)=\frac{1}{1+e^{-z}}\\
\frac{\partial f(x)}{\partial z}=f(x)[1-f(x)]\\
\frac{\partial f(x)}{\partial \mathbb{w}}=\frac{\partial f(x)}{\partial z}\cdot \frac{\partial z}{\partial \mathbb{w}}=f(x)\cdot [1-f(x)]\cdot x
$$
下面就来看看，如果用square error，会是怎样的。

![](.\pic\square-error.png)

然后就会发现问题存在——当拟合结果不好的时候，微分值也是零，也就是停止了update，这显然是不合理的。这说明了使用square error来对这样一个非线性函数进行评估会无效。

### Generative v.s. Discriminative

像上面利用Gaussian的方法称之为Generative Modeling (生成模型)，而后面这种$z=\mathbb{w^T}x+b$的拟合方法称之为Discriminative Modeling (判别模型)。实测效果而言，后者准确率79%优于前者的73%。

可以探讨下二者的关系。虽说看起来两个模型好像是一样的，其实有不同。首先我们可以看看discriminative方法是怎么来的，首先由generative方法中假设Gaussian之后，再假定协方差$\Sigma$相同，进而推出$z=\ln\frac{P(x|C_1)}{P(x|C_2)}+\ln\frac{P(C_1)}{P(C_2)}=\mathbb{w^T}x+b$

并且两种model的loss function是一样的，都是计算testing data的出现概率并使之最大，所以看上去好像是一样的，二者似乎是同构的。

其实不然，最大的区别就是，Generative限制了可能的分布必须符合Gaussian，这个范围显然是比较小的，也很可能和真是情况有出入，拟合效果不会达到最佳。而Discriminative则不同，事实上对比后发现，其实它只利用了一个重要的条件——即协方差$\Sigma$相同(当然了这是笼统的说法，但是大体是这个意思)。

就是说Discriminative其实并没有限制真实分布的搜索范围，因此拟合出来的效果更好也就理所当然了。并且，保留$\Sigma$相同是有道理的，因为在前面Modify Model的时候，我们发现令二者的协方差矩阵相同可以得到更好的结果。

当然了，以上是我个人的分析。

接下来说说老师的解释，Generative Model更像是我们进行了脑补(即Gaussian)，而Discriminative Model则是比较直接地根据data来估测。所以当dataset较大的时候，后者表现出来会更优，而当dataset比较小的时候，前者会有更好的结果。

### Multi-class Classification

上面举的例子主要是二元分类，下面简单提及多元分类。

这里要引进Softmax函数进行处理。

![](.\pic\softmax.png)

说到具体实现，多元分类的loss function与上面相同，都是采用cross entropy，首先是根据分类将每个数据所对应的$y$记作one-hot向量，再进行训练。

![](.\pic\multi-class.png)

至于为什么要使用one-hot向量，上面已经说了，如果采用连续整数，就相当于假定了数据之间的联系——即标记1和2比较近，和3比较远，但是实际上它们都是相互独立的。

接下来写一下对多元分类loss function的微分(n=3)
$$
y_i=\frac{e^{w_ix+b_i}}{\Sigma e^{w_ix+b_i}}\\
L(w_i,b_i)=-\Sigma\hat{y_i}\ln y_i\\
\frac{\partial L(w_i,b_i)}{\partial w_1}=-[\hat{y_1}\cdot (1-y_1)-(\hat{y_2}+\hat{y_3})\cdot y_1]\cdot x\\
\because \hat{y_1}+\hat{y_2}+\hat{y_3}=1 \\
\therefore \frac{\partial L(w_i,b_i)}{\partial w_1}=-[\hat{y_1}\cdot(1-y_1)-(1-\hat{y_1})\cdot y_1]\cdot x=-(\hat{y_1}-y_1)\cdot x  \\
\cdots\\
\frac{\partial L(w_i,b_i)}{\partial w_i}=-(\hat{y_i}-y_i)\cdot x
$$
事实上，和之前推导得出的二元分类的式子乃至linear regression的微分式子在形式上都是一致的。

### Limitation of Logistic Regression

这种分类方法有很大的局限性，最简单的一种无法正确分类情形就是下面的情况：

![](.\pic\limitation-of-logistic.png)

原因也十分显然——这种情况无法简单地用一条直线将二者分开，而logistic regression的分界线是一条直线。

#### Feature Transformation

在这里老师提到了一种处理的方法，就是对原有数据进行坐标变换(类似换参考系之类的)，例如将原有的坐标$(x,y)$变成(与点(0,0)的距离,与点(1,1)的距离)，这样一来就使得原本交叉在一起的数据能用一根直线分隔开。

但是需要处理的问题是——如何找到feature transformation的方案？

#### Cascading logistic regression models

![](.\pic\cascading.png)

一种直白的想法当然就是利用已学的内容，在前面铺多一层节点来进行处理。

这一部分老师讲的相对笼统，在具体实现上面仍存疑。但是理念已经是理解了。

## Deep Learning

接下来就是正式开始学习DL了。

### Ups and downs of Deep Learning

* 1958: Perceptron(linear model)
* 1969: Perceptron has limitation
* 1980: Multi-layer perceptron(like DNN today)
* 1986: Backpropagation(Usually more than 3 hidden layers is not helpful)
* 1989: 1 hidden layer is "good enough", why deep?
* 2006: RBM initialization(breakthrough)[石头汤（逃]
* 2009: GPU
* 2011: Start to be popular in speech recognition
* 2012: win ILSVRC image competition

### Three Steps for Deep Learning

1. define a set of function
2. goodness of function
3. pick the best function

### Neural Network

Different connection leads to different network structures.

#### Fully Connect Feedforward Network

全连接层。

![](.\pic\fully-connect.png)

在这种网络中，input是vector，output也是一个vector

### Matrix Operation

就是为了方便运算，采用了矩阵化的模式进行运算。

![](.\pic\matrix-operation.png)

一般按行排列对应neural的weight和bias，然后采用左乘。

处理的函数可以沿用sigmod，但是已不常用。

能用GPU加速的主要原因就是对矩阵运算进行加速。

### Output Layer

采用哲学层面来理解这个neural network，其实就是中间的hidden layers进行了feature extractor的工作，对feature进行了提炼，替代了人的feature engineering的工作。

![](.\pic\output-layer.png)

如果是做多元分类，最后往往还是要加上一个softmax的处理。

### Loss for an example

对于多元分类问题，同样是采用cross entropy来评估。

视频中采用了手写数字分类的问题为例。

![](.\pic\loss-1.png)

![](.\pic\loss-2.png)

至于更新方式当然也还是gradient descent。

### Backpropagation

老师没有详细介绍，一言以蔽之，就是一种便捷地计算微分的方法。

毕竟，通过叠千层饼，这个微分已经复杂到了一定程度，我等菜鸡要手算估计是天方夜谭了，还是掉包吧（逃

## Backpropagation

根据老师的说法，这就是一种gradient descent的优秀实现方法。

### Chain Rule

其实就是链式法则。

![](.\pic\chain-rule.png)

![](.\pic\back-pass.png)

### Forward pass

这个部分的微分是比较简单的。甚至可以总结规律来快速运算。
$$
z=w_1x_1+w_2x_2+b\\
\frac{\partial z}{\partial w_1}=x_1\\
\frac{\partial z}{\partial w_2}=x_2
$$
简单地说，这部分微分就是看weight所在那条连线的起点处的值是多少。

![](.\pic\forward-pass.png)

$C$表示最后的loss function，$z$表示中间结果，$\sigma(z)$表示某个neural的输出结果(sigmod函数处理)，那就可以利用chain rule写出下面的式子
$$
\frac{\partial C}{\partial w}=\frac{\partial C}{\partial z}\cdot\frac{\partial z}{\partial w}
$$
这个forward pass就是算后面那部分。

### Backward pass

这部分就是反向传播的核心部分了，即$\frac{\partial C}{\partial z}$，实际上就是一个递归求解的过程。
$$
a=\sigma(z)\\
\frac{\partial C}{\partial z}=\frac{\partial a}{\partial z}\cdot\frac{\partial C}{\partial a}\\
\frac{\partial a}{\partial z}=\frac{\partial \sigma(z)}{\partial z}=\sigma'(z)\\
\frac{\partial C}{\partial a}=\frac{\partial z^{\prime}}{\partial a} \frac{\partial C}{\partial z^{\prime}}+\frac{\partial z^{\prime \prime}}{\partial a} \frac{\partial C}{\partial z^{\prime \prime}}
$$
![](.\pic\backward-pass.png)

然后其实我们可以看出这是一个向后递归求解的过程，或者说**自后向前**的计算过程，说的好听一点，就是类似记忆化搜索。

![](.\pic\backward-1.png)

注意的是，在上图中，由于$z$已知，$\sigma'(z)$事实上就是一个const。

## Convolutional Neural Network

中文名即为卷积神经网络。主要用于处理图像，处理方式和DNN区别在于，CNN努力去简化网络架构。否则在进行图像处理的过程中，运算量太过于庞大。

有几个要点：

* Some patterns are much smaller than the whole image
* The same patterns appear in different regions
* Subsampling the pixels will not change the object(即缩小图像)

![](.\pic\CNN-1.png)

### Convolution

根据老师的说法，filter实际上是在做一个微型neural network的工作，相当于在图中检测filter所对应的feature是否存在。

![](.\pic\CNN-3.png)

![](.\pic\CNN-4.png)

由上图可以看出，convolution实际上就是neural network，需要注意到的是，由于使用同一个filter，这里每个neuron的weight都是相同的，这种情况叫做weight sharing，显然大幅减少了parameter的数目。

### Max Pooling

做完卷积之后，从局部区域选取最值，然后再组成新的matrix，这个过程叫做max pooling。据老师所说，这个操作是可以被微分的，后面再看看。

![](.\pic\max-pooling.png)

### Flatten

其实就是一个把二维图像(实则三维数据)拉直成一维vector的过程。

那显然会是一个很细长的玩意儿，然后这个就作为$x$被丢进一个全连接网络里面。

![](.\pic\flatten.png)

### What does CNN learn?

CNN的过程是黑箱的，总是无法直观理解，但是只有更好地理解才能够更高效地改进模型，因此，在这里老师给出了理解filter的一种方法。

![](.\pic\what-cnn-1.png)

例如，现在探究第k个filter的作用(也即对应什么feature)，那就取出这个filter。然后定义一个$a^k$表示这个filter处理过后所有输出值之和，称之为这张图片与第k个filter的契合度。接着，我们不断调整输入的假图片matrix(即$x$)使得$a^k$最大，采用gradient ascent的法子，那最终显然那个图片就体现了对应的feature。

在视频中，老师展示了三个部分对应的feature，例如convolution过程中filter对应的就是一些简单的纹路，然后全连接网络中的neuron对应的就是一些古怪的扭曲纹路。而最终，最让人吃惊的就是，网络的输出结果$y$，其实我们都知道对应的就是target，例如说手写数字识别从0到9，按理说输出的结果就是类似的数字图片。然而并不是。

![](.\pic\what-cnn-2.png)

可能这就是人为添加噪音的原理吧。

机器和人的思维方式不同，或许是采用的代数体系结构性问题（雾

当然老师也说了采用regularization的法子使得输出结果更方便辨识(手写数字)

相关标签：deep dream、deep style

### More Application : Playing Go

下围棋。

说实话，认真想想，围棋还真是很合适使用CNN，因为可以采用多元分类的法子，毕竟只有0和1两种状态，然后输出就是下一步在某位置的概率即可，像象棋的话就可能要做一些预处理。

#### Why CNN for playing Go?

用CNN做围棋，其实还有更深层的原因：

* Some patterns are much smaller than the whole image
* The same patterns appear in different regions.

![](.\pic\why-cnn.png)

这里要提及一点：显然围棋是不能够max pooling的，所以其实alpha go是没有这一步的，所以在做架构的时候要结合实际情况。

### More Application : Speech

在语音识别方面也可以使用CNN。

![](.\pic\why-cnn-1.png)

这里主要考虑让filter在frequency方向上移动，老师解释了这么操作的合理性——男生女生的不同音色导致频率不同。

很有意思，这启发我们在研究问题的时候，需要发散思维进行更广的思考，才可能更好的改进模型。

### More Application : Text

![](.\pic\why-cnn-2.png)

## Keras

接下来就是了解一下如何使用keras。

![](.\pic\keras-0.png)

其实这类深度学习框架都是类似的，这个keras和paddle是相同的，都是API，提供方便的接口，直接训练模型。所以主要是学习接口的使用。

### Mini-batch

就是把training set分成很多个batch进行训练。

首先就是随机去一些training data组成一个batch，然后计算这个batch内的loss，然后去更新parameter。这样子的效果其实之前已经提到过了，可以加速更新速度(好吧其实之前讲的是stochastic gradient descent，也就是batch=1的情况)。

把所有batch看过一次，就叫做一个epoch。

![](.\pic\keras-1.png)

这里老师提出了问题：看上去SGD速度很快，为什么不用SGD而是mini-batch？

### Speed

按理说，只要epoch一样，不管batch怎么设置，运算量是一样的，时间应该差不离，但是实际上差异很大。

![](.\pic\keras-2.png)

emmm，实际上这很显然就是硬件优化的问题了。因为GPU可以并行运算，所以这个结果也就显而易见了。

## Attack ML Models

任何一种产品出来，自然就要考虑遭受攻击的情况。ML自然也是如此。最直观的一种攻击就是——给出一张猫的图片，加上人为制造的噪音后，就会被机器辨识成鱼之类的。

![](.\pic\attack-0.png)

具体实现方法与deep dream很类似，都是固定参数值，然后去改变图片，当然了loss function是需要作出改变的。$C(y',y^{true})$指的是在程序看来目前图片与正确分类的相似度，所以加了个负号。然后$C(y',y^{false})$表示的是与错误标签的相似度，也就是通过这一项来引导程序作出错误判断。接着就是gradient descent来进行训练得出误导图。

当然了，这里还补充了一个评估值constraint，表示人类对图片差异的容忍程度。也就是说当这个值超过某个限度，可能人类就不会直接看出这是一只猫，那么用这张图再去欺骗程序就毫无意义了。所以需要限制住图片，使得这张图在人看了就是猫，但是程序就觉得是鱼。

这里还要探讨一下评估函数$d(x^0,x')$的选择。

![](.\pic\attack-1.png)

这里老师只介绍了两种选择，一是$l_2$范数，另一种就是L-infinity，即取误差最值。

然后老师举了一个例子来说明，对于图像处理可能后者更有成效。因为$l_2$范数来处理，可能会出现误差聚集在局部的情况，这对人类而言是十分明显的，例如右下角。

### How to Attack

事实上，我们要制作一张假图片$x'$，就是在约束条件下求解函数最值
$$
x^*=\arg \underset{d(x^0,x')\leq\varepsilon}{\min}L(x')
$$
而老师说，我们在做这个工作的时候，可以先忽略掉约束条件$d(x^0,x')\leq\varepsilon$，把这个问题当做一个常规的问题先进行解决。依旧是使用gradient descent。

这些参数$\theta$自然是不变的，然后$x'$从$x^0$开始。

然后再加上限制条件，如果发现超出了约束范围，就把那个点拉近。

![](.\pic\attack-2.png)

![](.\pic\attack-3.png)

### What happened?

![](.\pic\attack-4.png)

根据老师的解释，会发生这种attack的归因是，在不同维度的空间里，不同label占据的范围不同，所以random的noise干扰不会很大，但是人为制造的noise就会威力很大。

![](.\pic\attack-5.png)

### Attack Approaches

#### FGSM(Fast Gradient Sign Method)

据老师所说，这个方法是最简单的方法，看起来也是如此。

![](.\pic\attack-6.png)

使用这种方法，就只需要做一次update即可。那么多做几次会不会得到更好的结果呢？老师说确实是好的。

但是其实我觉得这个方法看起来太过于粗鲁，十分粗糙。如果那个$d(x^0,x')$是L-infinity，那就相当于这次update会去到四个顶点其中之一。

然后根据老师解释这种方法，其实可以看成是learning rate非常大，但是采用了约束来限制住它。因此可以一拳解决问题。

![](.\pic\attack-7.png)

### White Box v.s. Black Box

根据老师所说，像上面提到的根据已知参数来构造攻击，这种就叫做白箱攻击，然后其实和现实相去甚远。

不知道参数进行的攻击称为黑箱攻击，又要怎么实现呢？

![](.\pic\attack-8.png)

根据老师所说，只需要我们构建一个network，然后采用同样的data set来训练，那么使用这个proxy来构造攻击，成功率会非常高。

至于保护training data有用吗？老师又给了一种思路，如果这是一个开放的API，那么我们只需要给那个API投喂数据再利用返回结果来构造training dataset即可。

https://arxiv.org/pdf/1611.02770.pdf

### Universal Adversarial Attack

![](.\pic\attack-9.png)

这就是无差别攻击，构造一种噪声，让它可以对大多数图片都有效。

https://arxiv.org/abs/1610.08401

### Adversarial Reprogramming

这个说的是通过添加噪声改变网络的功能。

例如说本来网络的功能是辨识动物，然后你现在给出一些格子图，然后再附带上噪声，然后输入API，就能通过返回值知道有多少个格子。

即通过非侵入不改变参数的方式，来改变network的功能…听起来很像是sql注入式攻击。

![](.\pic\attack-10.png)

相关论文已下载。

### Attack in the Real World

老师进一步介绍了关于signal的广泛应用，上面提到的都是直接对图片进行的处理，然后构造出来的attack都是无损传输。那么问题来了，如果把这些attack图片打印出来，然后再拍照，signal是否还能发挥相应的作用呢？

答案是肯定的。

![](.\pic\attack-11.png)

上面是一个分类的具体案例。攻击确实生效了。

那么很自然的，就会想到去treat人脸识别系统。

![](.\pic\attack-12.png)

这个已经是有CMU大神做了出来了。

但是这其中是有很多困难的。

1. signal要足够显然，不然照相机拍照造成的信息丢失可能到时噪声损失
2. 这种色差要能够被打印机呈现出来之类的
3. 这种攻击要在不同角度上都成功

![](.\pic\attack-13.png)

还有一类攻击就是针对路标，来误导无人车。

![](.\pic\attack-14.png)

https://arxiv.org/abs/1707.08945

### Defense

讲完了攻击，就要谈谈如何进行防御了。常用的思路有两种：

1. 消极防御，也就是不变model，在外面套防护罩
2. 积极防御，在training过程中添加保护

![](.\pic\defense-0.png)

#### Passive Defense

一种最简单可行的方法就是使用个filter去平滑一下图片，让图片损失一些细节，那也就会顺带过滤掉signal了。

![](.\pic\defense-1.png)

当然还可以选择去辨识一个图片是不是attack，方法其实也是差不多的，三种处理：无处理、用filter 1处理、用filter 2处理，看看结果是不是差不多。如果差的很远，显然就是attack了。

![](.\pic\defense-2.png)

https://arxiv.org/abs/1704.01155

还有一种方法Randomization at Inference Phase，其实也差不多，就是给pic加上一些random signal，以此达到平均signal的效果，使得attack失效。

![](.\pic\defense-3.png)

https://arxiv.org/abs/1711.01991

#### Proactive Defense

这就是在训练network过程中修补漏洞。方式也十分直观，我们在训练过程中自行构造attack，然后再用attack作为training data去训练，感觉很像是在捏橡皮泥，不断平滑这个model的感觉。

![](.\pic\defense-4.png)

但是老师说，这种方法也是有缺陷的，例如你使用A方法来构造attack然后train，但是别人是用B方法来attack的话还是会成功。