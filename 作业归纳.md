[toc]

# HW1

这个作业的内容是预测PM2.5。

给出的数据包括了连续多天的各种空气污染物的指标，数据可以利用的方式有两种：

1. 利用18种污染物进行建模
2. 只使用PM2.5的数据进行处理

首先由经验可知，第一种方法总不会差，而我刚开始还觉得第二种方法好，因为说不定可以避免一些noise，果然还是太幼稚了。(在normalize使用std方法时，前者在training set上面的误差是5左右，后者是15)

事实上，直到HW2我看了TA的notes后才知道不同normalize也有很大影响，常用的方法大概有两种：

1. ```python
   mean=np.mean(x,axis=0)
   std=np.mean(x,axis=0)
   
   for i in range(x.shape[1]):
   	x[:,i]=(x[:,i]-mean[i])/(std[i]+0.01)
   ```

2. ```python
   Max=np.max(x,axis=0)
   Min=np.min(x,axis=0)
   
   for i in range(x.shape[1]):
   	x[:,i]=(x[:,i]-Min[i])/(Max[i]-Min[i]+0.01)
   ```

在这题中，实测发现第二种方法优于第一种。

并且我还尝试了使用二次曲线进行拟合，事实上效果并不好。下列表格一览，所示误差皆为kaggle上的结果。

|      LOSS       | normalize-1 | normalize-2 |
| :-------------: | :---------: | :---------: |
|     Linear      |  11.86449   |   9.08294   |
| Double Function |  11.73343   |   9.33989   |

以上所示都是private score，public score如下。

|      LOSS       | normalize-1 | normalize-2 |
| :-------------: | :---------: | :---------: |
|     Linear      |   9.92008   |   7.09186   |
| Double Function |   9.94314   |   8.09550   |

最好的组合就是采用18种污染物-采用第一种归一化-线性回归。

可惜还是有很大的问题，不管怎样在training set上的表现都不好，误差都在5以上，这显然就是老师所说的bias太大。

# HW2

这次的作业是一个二元分类问题，即通过各维度数据来判别工资水平。

首先要说到对于离散型参数(如学历水平)的处理方法：

* 变成离散的整数如1,2,3,4等
* 变成one-hot变量，也就是给每个学历都开一个列，用一个参数来对应一个学历，用0或1表示。

其实就根据经验而言，我觉得主要看这离散型参数的取值之间是否有优先级，是否相互独立。

举个例子，当讨论工资的时候，一般来说学历高工资高，所以前者可能就是蛮好的法子；但是一般来说一个人是北京人还是上海人，地区造成的差异不大，可以看成是相互独立的，这时候采用one-hot向量才是对的。

这次吸取了HW1的经验教训，在归一化的过程中尝试了两种方式，采用标准差的方式更优，体现在accuracy上是领先1%左右。

然后我主要是写了discriminative model，因为generative model比较僵硬固化，然后就偷懒没写了。

事实上，这次在训练过程中还需要采用正则化来约束参数。我对比了一下，二者的差异大概是0.7%左右。

另外，我个人在调试参数的时候，刚开始采用了adagrad的方法(下面第一种)，但是效果不优，在training set上面的accuracy也只有84%出头，后来采用了sqrt(step)的写法(下面第二种)，也只是84.9%左右，最后采用了答案提供的learning_rate，才堪堪上了85%。

1. ```python
   w-=learning_rate/sqrt(adagrad_sum)*gradient
   ```

2. ```python
   w-=learning_rate/sqrt(step)*gradient
   ```

但是在testing data上的表现却意外的好，让我感觉有点古怪…

另外就是在这次的答案中学到了分batch进行训练，其实在之前的视频里也有提到，但是我忘记了这回事…刚好这次就可以用上，对于这种非线性的模型可以显著提高训练速度，但是对于线性模型而言(如HW1)，效果就不怎样了。

最后在kaggle上面的结果是85.3%的accuracy，只比simple baseline高一些，但已经相对满足，希望接下来学习的知识可以继续帮助我改进model。