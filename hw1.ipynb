{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第一次作业-预测PM2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#萌新徒手抓瞎\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('train.csv')\n",
    "data=data[data[\"object-name\"]==\"PM2.5\"]\n",
    "data[[\"1\",\"2\"]][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 扒作业答案源码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data=np.genfromtxt(\"train.csv\",delimiter=',') #读入文件\n",
    "data=raw_data[1:,2:] #略去文件头和左侧属性名\n",
    "where_are_NaNs=np.isnan(data)\n",
    "data[where_are_NaNs]=0 #将无效值赋为零\n",
    "\n",
    "month_to_data={} #这个dict有三个维度，月份、污染物和时间\n",
    "\n",
    "for month in range(12): #数据中包含12个月\n",
    "    sample=np.empty(shape=(18,480))\n",
    "    for day in range(20): #每个月内含20天\n",
    "        for hour in range(24): #污染物有18种，因此每过一天就乘以18\n",
    "            sample[:,day*24+hour]=data[18*(month*20+day):18*(month*20+day+1),hour]\n",
    "    month_to_data[month]=sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.empty(shape=(12*471,18*9),dtype=float)\n",
    "y=np.empty(shape=(12*471,1),dtype=float)\n",
    "\n",
    "for month in range(12):\n",
    "    for day in range(20):\n",
    "        for hour in range(24):\n",
    "            if day==19 and hour>14: #471=12*20-10+1\n",
    "                continue\n",
    "            \n",
    "            #reshape(a,b)其中一个参数为-1意味着自适应另一维度来调整，如(1,-1)即变为一行\n",
    "            #x是取连续9小时内18种污染物的数值作为原始数据，且化为一行进行储存。两个维度分别是时间和污染物。\n",
    "            #y是取对应的第十小时PM2.5的数值作为结果\n",
    "            x[month*471+day*24+hour,:]=month_to_data[month][:,day*24+hour:day*24+hour+9].reshape(1,-1)\n",
    "            y[month*471+day*24+hour,0]=month_to_data[month][9,day*24+hour+9] #PM2.5在第九行\n",
    "\n",
    "            #总结一下上面这样处理的合理之处：所有连续9小时都被囊括，包括了跨天的时间段，最大化利用数据\n",
    "            #一切都归结于reshape的机智操作，赞！\n",
    "            \n",
    "# pd.DataFrame(x)\n",
    "#以前两行为例进行解释\n",
    "#第0行-第一种污染物从0点开始连续九小时的数值-第二种污染物从0点开始连续九小时的数值-\n",
    "#第1行-第一种污染物从1点开始连续九小时的数值-第二种污染物从1点开始连续九小时的数值-\n",
    "#以此类推就得到了训练用的dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=np.mean(x,axis=0) #dataset中每一列都是同种污染物的数值\n",
    "std=np.std(x,axis=0)\n",
    "\n",
    "for i in range(x.shape[0]): #x.shape[0]=12*471\n",
    "    for j in range(x.shape[1]): #x.shape[1]=18*9\n",
    "        x[i][j]=(x[i][j]-mean[j])/(std[j]+0.0001) #归一化处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T= 0\n",
      "Loss: 27.071214829194115\n",
      "(10, 5750)\n",
      "T= 5000\n",
      "Loss: 5.737230072636322\n",
      "(163, 1)\n",
      "T= 10000\n",
      "Loss: 5.683826252203138\n",
      "(163, 1)\n",
      "T= 15000\n",
      "Loss: 5.681715033739906\n",
      "(163, 1)\n",
      "T= 20000\n",
      "Loss: 5.681030482545131\n",
      "(163, 1)\n",
      "T= 25000\n",
      "Loss: 5.6805853353390665\n",
      "(163, 1)\n",
      "T= 30000\n",
      "Loss: 5.680273034497946\n",
      "(163, 1)\n",
      "T= 35000\n",
      "Loss: 5.680052459541523\n",
      "(163, 1)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-2483bb1f9d58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mgradient\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0madagrad_sum\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madagrad_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dim=x.shape[1]+1\n",
    "w=np.zeros(shape=(dim,1))\n",
    "x=np.concatenate((np.ones((x.shape[0],1)),x),axis=1).astype(float) #左侧拼接bias项所对应的常数1\n",
    "learning_rate=np.array([[200]]*dim)\n",
    "adagrad_sum=np.zeros(shape=(dim,1))\n",
    "\n",
    "#下面就是进行Gradient Descent\n",
    "#矢量化操作需要常记的一些点\n",
    "#1.dataset中的实例作为行，即一行一个实例，然后参数作为列，或者调转，最好形成固定习惯\n",
    "#2.记住计算平方就是A.T@A，即转置后直接矩阵乘法\n",
    "#3.如果直接在dataset左侧拼接常数1，那么各种操作都会方便许多\n",
    "\n",
    "for T in range(100000):\n",
    "    if T%5000==0:\n",
    "        print(\"T=\",T)\n",
    "        print(\"Loss:\",np.sqrt(np.sum(np.power(x.dot(w)-y,2))/x.shape[0]))\n",
    "    gradient=(-2)*np.transpose(x).dot(y-x.dot(w))\n",
    "    adagrad_sum+=gradient**2\n",
    "    w=w-learning_rate/(np.sqrt(adagrad_sum)+0.0005)*gradient\n",
    "\n",
    "np.save('weight.npy',w) #训练得到的权重存储在特定后缀文件.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.load('weight.npy')\n",
    "test_raw_data=np.genfromtxt('test.csv',delimiter=',')\n",
    "test_data=test_raw_data[1:,2:]\n",
    "where_are_NaNs=np.isnan(test_data)\n",
    "test_data[where_are_NaNs]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (240,163) and (10,1) not aligned: 163 (dim 1) != 10 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-2880856ccc63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0manswer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (240,163) and (10,1) not aligned: 163 (dim 1) != 10 (dim 0)"
     ]
    }
   ],
   "source": [
    "test_x=np.empty(shape=(240,18*9),dtype=float)\n",
    "\n",
    "for i in range(240):\n",
    "    test_x[i,:]=test_data[i*18:(i+1)*18,:].reshape(1,-1)\n",
    "    \n",
    "mean=np.mean(test_x,axis=0)\n",
    "std=np.std(test_x,axis=0)\n",
    "\n",
    "for i in range(test_x.shape[0]):\n",
    "    for j in range(test_x.shape[1]):\n",
    "        if not std[j]==0:\n",
    "            test_x[i][j]=(test_x[i][j]-mean[j])/std[j]\n",
    "            \n",
    "test_x=np.concatenate((np.ones(shape=(test_x.shape[0],1)),test_x),axis=1).astype(float)\n",
    "answer=test_x.dot(w)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(\"ans.csv\",\"w+\")\n",
    "ws=csv.writer(f)\n",
    "title=['id','value']\n",
    "ws.writerow(title)\n",
    "\n",
    "for i in range(240):\n",
    "    content=['id_'+str(i),answer[i][0]]\n",
    "    ws.writerow(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## z君独立尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "data_raw=np.genfromtxt(\"train.csv\",delimiter=',')\n",
    "data=data_raw[1:,2:]\n",
    "where_are_NaNs=np.isnan(data)\n",
    "data[where_are_NaNs]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_hour_data=[]\n",
    "\n",
    "for i in range(240):\n",
    "    con_hour_data.append(data[i*18+9,:])\n",
    "\n",
    "con_hour_data=np.array(con_hour_data).reshape(1,-1)\n",
    "\n",
    "x_train=np.zeros((5750,9)) #这里需要非常注意，如果有列向量之类的，不要使用np.array方法进行转换，而是直接用np.zeros方法创建！\n",
    "y_train=np.zeros((5750,1))\n",
    "\n",
    "for i in range(con_hour_data.shape[1]-10):\n",
    "    x_train[i,0:9]=con_hour_data[0,i:i+9]\n",
    "    y_train[i]=con_hour_data[0,i+9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=np.mean(x_train,axis=1)\n",
    "std=np.std(x_train,axis=1)\n",
    "\n",
    "# print(mean.shape)\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    x_train[i]=(x_train[i]-mean[i])/(std[i]+0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T:0\n",
      "Loss:27.128038\n",
      "T:5000\n",
      "Loss:15.025482\n",
      "T:10000\n",
      "Loss:15.025482\n",
      "T:15000\n",
      "Loss:15.025482\n",
      "T:20000\n",
      "Loss:15.025482\n",
      "T:25000\n",
      "Loss:15.025482\n",
      "T:30000\n",
      "Loss:15.025482\n",
      "T:35000\n",
      "Loss:15.025482\n",
      "T:40000\n",
      "Loss:15.025482\n",
      "T:45000\n",
      "Loss:15.025482\n",
      "T:50000\n",
      "Loss:15.025482\n",
      "T:55000\n",
      "Loss:15.025482\n",
      "T:60000\n",
      "Loss:15.025482\n",
      "T:65000\n",
      "Loss:15.025482\n",
      "T:70000\n",
      "Loss:15.025482\n",
      "T:75000\n",
      "Loss:15.025482\n",
      "T:80000\n",
      "Loss:15.025482\n",
      "T:85000\n",
      "Loss:15.025482\n",
      "T:90000\n",
      "Loss:15.025482\n",
      "T:95000\n",
      "Loss:15.025482\n"
     ]
    }
   ],
   "source": [
    "w=np.zeros((10,1))\n",
    "x_train=np.concatenate((np.ones((x_train.shape[0],1)),x_train),axis=1).astype(float)\n",
    "\n",
    "learning_rate=np.array([[100]]*10)\n",
    "adagrad=np.zeros((10,1))\n",
    "\n",
    "for T in range(100000):\n",
    "    if T%5000==0:\n",
    "        print(\"T:%d\" % T)\n",
    "        print(\"Loss:%f\" % (np.sqrt(np.sum(np.power(y_train-x_train@w,2))/x_train.shape[0])))\n",
    "    \n",
    "    gradient=(-2)*np.transpose(x_train)@(y_train-x_train@w)\n",
    "    adagrad+=gradient**2\n",
    "    \n",
    "    w-=learning_rate/np.sqrt(adagrad+0.00001)*gradient\n",
    "    \n",
    "np.save(\"weight.npy\",w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
